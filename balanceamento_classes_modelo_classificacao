dados_balanceado <- DMwR::SMOTE(target ~. , data = df_treino)


# modelo
modelo <- randomForest(target ~ ., data = dados_balanceado)
modelo

# Avaliando o modelo
plot(modelo)

# Previsões com dados de teste
previsoes <- predict(modelo, dados_teste)

# Confusion Matrix
?caret::confusionMatrix
cm <- caret::confusionMatrix(previsoes, dados_teste$target, positive = "1")
cm


# Calculando Precision, Recall e F1-Score, métricas de avaliação do modelo preditivo
y <- dados_teste$inadimplente
y_pred <- previsoes

precision <- posPredValue(y_pred, y)
precision

recall <- sensitivity(y_pred, y)
recall

F1 <- (2 * precision * recall) / (precision + recall)
F1

# Importância das variáveis preditoras para as previsões
View(dados_treino_bal)
varImpPlot(modelo)

# Obtendo as variáveis mais importantes
imp_var <- importance(modelo)
varImportance <- data.frame(Variables = row.names(imp_var), 
                            Importance = round(imp_var[ ,'MeanDecreaseGini'],2))

# Criando o rank de variáveis baseado na importância
rankImportance <- varImportance %>% 
  mutate(Rank = paste0('#', dense_rank(desc(Importance))))

# Usando ggplot2 para visualizar a importância relativa das variáveis

ggplot(rankImportance, 
       aes(x = reorder(Variables, Importance), 
           y = Importance, 
           fill = Importance)) + 
  geom_bar(stat='identity') + 
  geom_text(aes(x = Variables, y = 0.5, label = Rank), 
            hjust = 0, 
            vjust = 0.55, 
            size = 4, 
            colour = 'red') +
  labs(x = 'Variables') +
  coord_flip() 






